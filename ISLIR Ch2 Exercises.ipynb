{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLIR ch 2 Exercises\n",
    "Conceptual:\n",
    "\n",
    "(note: https://github.com/jstjohn/IntroToStatisticalLearningR-/blob/master/R_Exercises/Exercise1/Exercise1.Rmd can be used to compare answers, but no peeking! =D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3:\n",
    "Provide a sketch of typical squared bias, variance, training error, test error, and bayes (or irreducible) error curves on a single plot, as we go from less flexible approaches to more flexible approaches.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/model_bias_variance_graph.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does it look this way?\n",
    "Well, as flexibility increases, training error decreases, as our model gets more and more capable of responding to small differences in the training data. random forest can produce models that linear regression just can't.\n",
    "\n",
    "But, that results in increased variance, as our model is going to be much more responsive to the training data we get.\n",
    "By the same token, bias decreases. Our model has fewer automatic assumptions coming in, that's what allows for this flexibility.\n",
    "\n",
    "Test error is mthe most interesting and important case. It starts high, as the model fails to capture the relationship in the data because it's too simple. (though it's still lower than training data).\n",
    "\n",
    "Around the same level of complexity at which the training data starts to be well described by the model, and the training error falls, so too does the test error fall.\n",
    "\n",
    "However, at some point, the model becomes too flexible, and while training error continues to reduce, test error begins to increase, as the relationships learned by the model in training fail to generalize to the test data. This is the definition of overfitting.\n",
    "\n",
    "I was the least confident regarding irreducible error, but the link I have up top said this is the simplest case, as it doesn't matter what the model is, this error isn't getting reduced. That makes sense, I guess, but I feel like I still have more to learn re: what irreducible error is, where it comes from, what it looks like, how it's measured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: \n",
    "    Describe three real life applications in which classification might be useful\n",
    "       describe the response, and the predictors. Is the goal inference or prediction? Explain your answer.\n",
    "       \n",
    "       1: Classifying credit card transactions as real or fraudulent.\n",
    "           The response would be a label, real or fraudulent.\n",
    "           The predictors would be who the transaction is addressed to, the amount, time of day, address of charger...\n",
    "               And then, to make this actually work, you would need to generate other predictors...\n",
    "               \n",
    "               \"been_charged_before\" if 1, less likely to be fraud, if not, more likely\n",
    "               \"same_state/country\" if 1, less likely, if 0, more likely\n",
    "               \"typical_amount\" if 1, less likely, if 0, more likey.\n",
    "               \n",
    "            The goal here would be prediction, as we want to generate a flag that will send the credit card holder an annoying, \n",
    "            but potentially important, email.\n",
    "            \n",
    "       2: I want to do an example of inference... Classifying shows on netflix as 'viral' or not.\n",
    "           The response would be a label of shows that we know are highly recommended on social media (we'd have to come up with \n",
    "               some metric of virality... a certain quotient, say # of people recommended * % a recommend leads to a watch. not sure where we'd get that data, but this is just made up)\n",
    "               \n",
    "               The predictors could be a lot of things.\n",
    "                   genre\n",
    "                   age of main characters\n",
    "                   gender of main characters\n",
    "                   number of main characters\n",
    "                   period in which the show is set\n",
    "                   number of episodes released\n",
    "                   original date of publication\n",
    "                   studio\n",
    "                   country of origin\n",
    "                   \n",
    "            We could train a model to classify whether shows are going to get this viral label using a random forest, and then use feature importance to see which of these factors are most important.\n",
    "\n",
    "two is plenty, I get it.\n",
    "\n",
    "Now do the same for regression\n",
    "\n",
    "1) suppose you wanted to see how many likes a tweet would get.\n",
    "    response: number of likes\n",
    "    predictors: \n",
    "        - number of followers\n",
    "        - number of characters in tweet\n",
    "        - number of tweets that day/hour\n",
    "    \n",
    "    Goal here could be prediction or inference. you could set something up to give you an estimate of how your tweet would do, or you could more generally inspect the importance of these factors\n",
    "    \n",
    "one is plenty I get it.\n",
    "\n",
    "Now. cluster analysis\n",
    "    Suppose you wanted to understand the different groups of people visiting website.\n",
    "        output: cluster label\n",
    "            input: time of day, time spent, previous website visited, etc etc.\n",
    "            \n",
    "      you could pick the number of clusters with the best fit, by purity on each feature I think?\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred? A less flexible approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of a more flexible model is that it can capture more complex relationships. For example, if in fact there exists an interaction between predictors and the response, a simple y ~ X1 + X2 isn't going to explain your data well. Your error is going to be high.\n",
    "\n",
    "However, increasing the complexity by adding (X1 x X2) might get you what you're looking for. That is, it might capture the relationship, though it will increase the flexibility. To use a more ML example, random forest might be able to capture, by partitioning, the relationship between the predictors and the features, in a way that LR won't.\n",
    "\n",
    "A less flexible approach may preferred if you're overfitting. in those cases, you have too much flexibility.\n",
    "\n",
    "I think its also fair to say that less flexible approaches are more human-interpretable, so that might be taken into account as well, depending on your goal.\n",
    "\n",
    "Ah, that link I included rightly states that more flexible approaches tend to have higher accuracy, so they might be preferrable for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification?\n",
    "\n",
    "Well, we generally assume that our data is normally distributed. To be honest, I'm not sure why we do that other than that 1) it's easier, and 2) it's *often* correct...\n",
    "\n",
    "The advantage is that if we're right, we can use what we know about normal distributions to get, for example, t-values.\n",
    "\n",
    "From the link:\n",
    "\n",
    "\"They are more resitrictive, but as a result fewer observations of underlying data are required to fit them fairly well. Nonparametric methods are sometimes required when the underlying data is very different from what can be fit with parametric techniques, or when the underlying distribution is unknown but obviously not normally distributed.\"\n",
    "\n",
    "So is there anything we're missing?\n",
    "\n",
    "I think the key thing is that you're making assumptions, but if they're correct, you can learn a lot about your data with a small(ish) sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Given some data, do some calculations!\n",
    "\n",
    "wow! python time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist = [('Obs.', range(6)),\n",
    "          ('X1',[0,2,0,0,-1,1]),\n",
    "          ('X2',[3,0,1,1,0,0]),\n",
    "          ('X3',[0,0,3,2,1,2]),\n",
    "          ('Y',['Red','Red','Red','Green','Green','Red'])\n",
    "         \n",
    "         \n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame.from_items(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs.</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Obs.  X1  X2  X3      Y\n",
       "0     0   0   3   0    Red\n",
       "1     1   2   0   0    Red\n",
       "2     2   0   1   3    Red\n",
       "3     3   0   1   2  Green\n",
       "4     4  -1   0   1  Green\n",
       "5     5   1   0   2    Red"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as scipy_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3, 0)\n",
      "3.0\n",
      "(2, 0, 0)\n",
      "2.0\n",
      "(0, 1, 3)\n",
      "3.16227766017\n",
      "(0, 1, 2)\n",
      "2.2360679775\n",
      "(-1, 0, 1)\n",
      "1.41421356237\n",
      "(1, 0, 2)\n",
      "2.2360679775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0,\n",
       " 2.0,\n",
       " 3.1622776601683795,\n",
       " 2.2360679774997898,\n",
       " 1.4142135623730951,\n",
       " 2.2360679774997898]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(len(df1)):\n",
    "    \n",
    "    a=(0,0,0)\n",
    "    b=(df1['X1'].iloc[i],\n",
    "      df1['X2'].iloc[i],\n",
    "      df1['X3'].iloc[i])\n",
    "    print(b)\n",
    "    dst=scipy_distance.euclidean(a,b)\n",
    "    print(dst)\n",
    "    output.append(dst)\n",
    "output\n",
    "#    dst=distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3484692283495345"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    0\n",
       "3    0\n",
       "4   -1\n",
       "5    1\n",
       "Name: X1, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['X1'].iloc[range(len(df1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def getNeighbors(trainingSet, testInstance,k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dst=scipy_distance.euclidean(testInstance, trainingSet[x][0:3])\n",
    "        distances.append((trainingSet[x],dst))\n",
    "    #print(distances)    \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    #print(distances)\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSet=[[df1.iloc[0]['X1'],\n",
    "           df1.iloc[0]['X2'],\n",
    "           df1.iloc[0]['X3'],\n",
    "           df1.iloc[0]['Y']],\n",
    "           [df1.iloc[1]['X1'],\n",
    "           df1.iloc[1]['X2'],\n",
    "           df1.iloc[1]['X3'],\n",
    "           df1.iloc[1]['Y']],\n",
    "           [df1.iloc[2]['X1'],\n",
    "           df1.iloc[2]['X2'],\n",
    "           df1.iloc[2]['X3'],\n",
    "           df1.iloc[2]['Y']],\n",
    "           [df1.iloc[3]['X1'],\n",
    "           df1.iloc[3]['X2'],\n",
    "           df1.iloc[3]['X3'],\n",
    "           df1.iloc[3]['Y']],\n",
    "           [df1.iloc[4]['X1'],\n",
    "           df1.iloc[4]['X2'],\n",
    "           df1.iloc[4]['X3'],\n",
    "           df1.iloc[4]['Y']],\n",
    "\n",
    "           [df1.iloc[5]['X1'],\n",
    "           df1.iloc[5]['X2'],\n",
    "           df1.iloc[5]['X3'],\n",
    "           df1.iloc[5]['Y']]\n",
    "         ]\n",
    "testInstance = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 0, 1, 'Green']]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = getNeighbors(trainSet, testInstance,1)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute euclidean distance between each observation and the test point [0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 2.0, 3.1622776601683795, 2.2360679774997898, 1.4142135623730951, 2.2360679774997898]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output =[]\n",
    "\n",
    "for each in range(len(trainSet)):\n",
    "    \n",
    "    result = scipy_distance.euclidean([0,0,0],trainSet[each][0:3])\n",
    "    output.append(result)\n",
    "                  \n",
    "print(output)\n",
    "df1['dist_to_0'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs.</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "      <th>dist_to_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Red</td>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>2.236068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>2.236068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Obs.  X1  X2  X3      Y  dist_to_0\n",
       "0     0   0   3   0    Red   3.000000\n",
       "1     1   2   0   0    Red   2.000000\n",
       "2     2   0   1   3    Red   3.162278\n",
       "3     3   0   1   2  Green   2.236068\n",
       "4     4  -1   0   1  Green   1.414214\n",
       "5     5   1   0   2    Red   2.236068"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our prediction with k = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 0, 1, 'Green']]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not sure what they mean by prediction.... I guess they mean for [0,0,0]\n",
    "testInstance=[0,0,0]\n",
    "neighbors= getNeighbors(trainSet, testInstance,1)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ohhh I see now. NEeded more code.\n",
    "import operator\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    \n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Green', 1)]\n"
     ]
    }
   ],
   "source": [
    "testInstance=[0,0,0]\n",
    "neighbors= getNeighbors(trainSet, testInstance,1)\n",
    "response = getResponse(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for why this is occuring, in this case we are taking the \"majority vote\" of just one item, which happens to be green, because -1,0,1 is the closest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 0, 1, 'Green'],\n",
       " [2, 0, 0, 'Red'],\n",
       " [0, 1, 2, 'Green'],\n",
       " [1, 0, 2, 'Red'],\n",
       " [0, 3, 0, 'Red']]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInstance=[0,0,0]\n",
    "neighbors= getNeighbors(trainSet, testInstance,5)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Red', 3), ('Green', 2)]\n"
     ]
    }
   ],
   "source": [
    "response = getResponse(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the bayes decision boundary in this problem is highly non-linear, then what would we expect the best value for K to be? Large or small?\n",
    "\n",
    "\n",
    "If it's highly non-linear, we can't rely on just our local environment. Zoom in on a curve enough and it looks like a line. Therefore, it makes sense to me that we want a relatively large k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
